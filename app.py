import streamlit as st
from gtts import gTTS
import openai
import os
from pydub import AudioSegment
from io import BytesIO
import base64

# ğŸ¼ ConfiguraciÃ³n de la app
st.set_page_config(page_title="BAE | BebÃ© Asistente Emocional", page_icon="ğŸ¼", layout="centered")

# ğŸŒˆ Estilo pastel BAE
st.markdown("""
<style>
body {
    background: linear-gradient(135deg, #fff7da, #fef3e2, #e4f6ff, #dff7ec);
    background-size: 400% 400%;
    animation: gradientMove 12s ease infinite;
}
@keyframes gradientMove {
    0% {background-position: 0% 50%;}
    50% {background-position: 100% 50%;}
    100% {background-position: 0% 50%;}
}
h1 {
    text-align: center;
    color: #2c423f;
    font-weight: 800;
    font-family: 'Poppins', sans-serif;
}
.big-button button {
    background: linear-gradient(135deg, #fddf91, #fbc687);
    border: none;
    color: #2c423f;
    font-size: 1.2rem;
    font-weight: 600;
    padding: 0.8rem 2rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    box-shadow: 0 6px 15px rgba(250,180,100,0.3);
}
.big-button button:hover {
    transform: scale(1.05);
    background: linear-gradient(135deg, #ffe5a3, #ffd4a2);
}
.response-box {
    background-color: rgba(255,255,255,0.6);
    border-radius: 16px;
    padding: 1.5rem;
    margin-top: 1rem;
    color: #2c423f;
    font-size: 1.1rem;
    text-align: center;
    font-family: 'Nunito', sans-serif;
}
</style>
""", unsafe_allow_html=True)

# ğŸ§¸ Encabezado
st.markdown("<h1>ğŸ¼ BAE â€” BebÃ© Asistente Emocional</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center; color:#2c423f;'>Habla con BAE: puede contarte cuentos, poner mÃºsica o ayudarte a cuidar al bebÃ© ğŸ’›</p>", unsafe_allow_html=True)

# ğŸ”‘ Clave de API
api_key = st.text_input("ğŸ”‘ Ingresa tu clave de OpenAI", type="password", placeholder="sk-...")
if api_key:
    openai.api_key = api_key

# ğŸ™ï¸ GrabaciÃ³n de voz
audio_file = st.audio_input("Habla con BAE (haz tu pregunta o pide algo)", help="Puedes decir: 'cuÃ©ntame un cuento', 'quÃ© temperatura tiene el bebÃ©', 'pon mÃºsica suave'")

# ğŸ”„ Procesamiento
if st.button("ğŸ’« Procesar Audio", key="procesar", help="Haz clic para que BAE procese tu voz", use_container_width=True):
    if not api_key:
        st.warning("Por favor ingresa tu API key antes de continuar ğŸ—ï¸")
    elif not audio_file:
        st.info("ğŸ™ï¸ Graba tu voz para que BAE pueda escucharte.")
    else:
        with st.spinner("ğŸ§ BAE estÃ¡ escuchando..."):
            # Guardar audio temporalmente
            with open("input.wav", "wb") as f:
                f.write(audio_file.getbuffer())

            # ğŸ”Š AquÃ­ puedes integrar tu modelo de reconocimiento de voz o texto
            # Por simplicidad, simulamos texto procesado:
            user_text = "BAE, cuÃ©ntame un cuento sobre un osito que tiene sueÃ±o"

            # ğŸ¤– Llamar al modelo de OpenAI
            prompt = f"Eres BAE, un asistente tierno, calmado y con voz maternal. Responde como si hablaras a un bebÃ© o a su cuidador. Pregunta: {user_text}"
            response = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}]
            )
            answer = response.choices[0].message.content

            # ğŸ¼ Mostrar respuesta
            st.markdown('<div class="response-box">ğŸ§¸ ' + answer + '</div>', unsafe_allow_html=True)

            # ğŸ¤ Generar respuesta hablada
            tts = gTTS(answer, lang="es")
            audio_buffer = BytesIO()
            tts.write_to_fp(audio_buffer)
            audio_buffer.seek(0)

            st.audio(audio_buffer, format="audio/mp3")

            # ğŸ’« AnimaciÃ³n de ternura (simple efecto de texto)
            st.markdown("<p style='text-align:center; font-size:1.2rem; color:#2c423f;'>ğŸ’› BAE sonrÃ­e y te mira con ternura ğŸ’›</p>", unsafe_allow_html=True)


